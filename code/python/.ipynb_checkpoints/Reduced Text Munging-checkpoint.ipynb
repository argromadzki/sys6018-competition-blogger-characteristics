{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tasks:\n",
    "\n",
    "-- Date preprocessing -- \n",
    "    converting dates between languages, and then structure\n",
    "    --> alternatively, we can duplicate the set, change weird dates to none\n",
    "    \n",
    "--feature creation--\n",
    "    date by year\n",
    "    looking at if they are posting weekday/weekend might suggest that they are working age\n",
    "    language (foreign in general or specifics)\n",
    "    number of posts per user.id\n",
    "    \n",
    "-- text --\n",
    "    remove the stopwords\n",
    "        NLTK\n",
    "    remove the punctuation\n",
    "    stemming the words\n",
    "    SVD (singular value decomposition) --> will show what is most important by \n",
    "        taking the matrix of term counts (needs to be created), but returns importance values ~ variability with each word\n",
    "    TF-IDF: could filter down to top 500-1000 words (we can probably just implement using a package) \n",
    "        if not...\n",
    "        calculate the frequency of word in every document\n",
    "        inverse log \n",
    "        \n",
    "-- train model: multiple linear regression --\n",
    "    glm net --> just make sure not to do log, but can still use this for normal parametric\n",
    "        (generalization of ridge and lasso regression)\n",
    "    \n",
    "    CV procedure to judge accuracy of predictor based on words we keep or parameters of the linear model\n",
    "\n",
    "    \n",
    "general notes: what is a document?\n",
    "\n",
    "    post?\n",
    "        -this would let us use the distribution of predictions for a user to do a second layer to the model\n",
    "        -potentially average/take median of different predictions for individual documents\n",
    "        \n",
    "        -might want to consider the number of unique pairings between user.id and post.id\n",
    "        \n",
    "    single user?\n",
    "    \n",
    "    bigrams or trigrams instead of words (two or three words in order can be treated as words)\n",
    "        n words in sentence --> n-1 bigrams --> blows up dimensionality, but could give more information because context\n",
    "        comes into play (may or may not be feasible depending on our corpus)\n",
    "        \n",
    "        \n",
    "Note from Sean: We may want to use the \"gensim\" package, which is Google's pre-trained word2vec model, which I think could be really useful.\n",
    "\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as slr\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set wd\n",
    "os.chdir(\"C://Users/alxgr//Documents//UVA//DSI//Fall 2018//SYS//Kaggle Competition 3//sys6018-competition-blogger-characteristics//data\")\n",
    "# os.chdir(\"/Users/SM/DSI/classes/fall2018/SYS6018/kaggle/sys6018-competition-blogger-characteristics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "# train = pd.read_csv(os.path.join(\"data\", \"input\", \"train.csv\"))\n",
    "# test = pd.read_csv(os.path.join(\"data\", \"input\", \"test.csv\"))\n",
    "\n",
    "# (os.path did not work for alex.  below for wd on alex's pc)\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join data sets\n",
    "test['age'] = None\n",
    "train['set'] = \"train\"\n",
    "test['set'] = \"test\"\n",
    "# train.shape\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.concat([train, test])\n",
    "# alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post.id         0\n",
       "user.id         0\n",
       "gender          0\n",
       "topic           0\n",
       "sign            0\n",
       "date            0\n",
       "text            0\n",
       "age        238323\n",
       "set             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post.id</th>\n",
       "      <th>user.id</th>\n",
       "      <th>gender</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>set</th>\n",
       "      <th>date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16332</td>\n",
       "      <td>male</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>33</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post.id  user.id gender              topic      sign          date  \\\n",
       "0        1    11869   male            Student       Leo   14,May,2004   \n",
       "1        2    11869   male            Student       Leo   13,May,2004   \n",
       "2        3    11869   male            Student       Leo   12,May,2004   \n",
       "3        4    11869   male            Student       Leo   12,May,2004   \n",
       "4        5    16332   male  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text age    set date_parsed  \n",
       "0             Info has been found (+/- 100 pages,...  15  train        None  \n",
       "1             These are the team members:   Drewe...  15  train        None  \n",
       "2             In het kader van kernfusie op aarde...  15  train        None  \n",
       "3                   testing!!!  testing!!!            15  train        None  \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  33  train        None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimenting with the dateparser package\n",
    "alldata[\"date_parsed\"] = None\n",
    "# alldata.date_parsed\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14,May,2004'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateparser\n",
    "\n",
    "# print(str(alldata.date[0]))\n",
    "# print(dateparser.parse(str(alldata.date[0])))\n",
    "\n",
    "# train[\"date\"][0]\n",
    "\n",
    "# for i in range(0,len(alldata)):\n",
    "#     alldata.date_parsed[i] = dateparser.parse(str(alldata.date[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ the issue here is that the objects being passed in at each index are actually 2 objects...?!\n",
    "\n",
    "where is the second one coming from?\n",
    "\n",
    "I think when we combined training and observation, there are two indices with value of 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    train\n",
      "1     test\n",
      "Name: set, dtype: object\n",
      "13,May,2004\n"
     ]
    }
   ],
   "source": [
    "# print(alldata.set[0]) # confirmed, indices need to be reset in the \"all\" data set\n",
    "alldata.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alldata.date[0]) # confirmed, the index now only returns one value per index\n",
    "\n",
    "for i in range(0,len(alldata)):\n",
    "#     alldata.date_parsed[i] = dateparser.parse(str(alldata.date[i])) # produces SettingWithCopyWarning\n",
    "    alldata.loc[i,('data_parsed')] = dateparser.parse(str(alldata.date[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post.id</th>\n",
       "      <th>user.id</th>\n",
       "      <th>gender</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>set</th>\n",
       "      <th>date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>2004-05-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>2004-05-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>2004-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11869</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>2004-05-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16332</td>\n",
       "      <td>male</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>33</td>\n",
       "      <td>train</td>\n",
       "      <td>2004-06-11 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  post.id  user.id gender              topic      sign          date  \\\n",
       "0      0        1    11869   male            Student       Leo   14,May,2004   \n",
       "1      1        2    11869   male            Student       Leo   13,May,2004   \n",
       "2      2        3    11869   male            Student       Leo   12,May,2004   \n",
       "3      3        4    11869   male            Student       Leo   12,May,2004   \n",
       "4      4        5    16332   male  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text age    set  \\\n",
       "0             Info has been found (+/- 100 pages,...  15  train   \n",
       "1             These are the team members:   Drewe...  15  train   \n",
       "2             In het kader van kernfusie op aarde...  15  train   \n",
       "3                   testing!!!  testing!!!            15  train   \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  33  train   \n",
       "\n",
       "           date_parsed  \n",
       "0  2004-05-14 00:00:00  \n",
       "1  2004-05-13 00:00:00  \n",
       "2  2004-05-12 00:00:00  \n",
       "3  2004-05-12 00:00:00  \n",
       "4  2004-06-11 00:00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head() # it works thank the lord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime, leaving non-valid/non-English dates null\n",
    "alldata['date_date'] = pd.to_datetime(alldata.date, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442961, 9) \n",
      " (438492, 10)\n"
     ]
    }
   ],
   "source": [
    "# I would recommend removing NA's this way -- it is much easier.\n",
    "alldata.dropna(inplace = True) \n",
    "print(train.shape,\"\\n\",alldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables:\n",
    "\n",
    "'''\n",
    "Gender\n",
    "Topic\n",
    "Sign\n",
    "~Date (depending on how we encode it)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corrected = alldata[alldata.set == 'train']\n",
    "testing_corrected = alldata[alldata.set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         post.id  user.id  gender              topic      sign       date  \\\n",
       "0             1    11869    male            Student       Leo 2004-05-14   \n",
       "1             2    11869    male            Student       Leo 2004-05-13   \n",
       "2             3    11869    male            Student       Leo 2004-05-12   \n",
       "3             4    11869    male            Student       Leo 2004-05-12   \n",
       "4             5    16332    male  InvestmentBanking  Aquarius 2004-06-11   \n",
       "5             6    16332    male  InvestmentBanking  Aquarius 2004-06-10   \n",
       "6             7    16332    male  InvestmentBanking  Aquarius 2004-06-10   \n",
       "7             8    16332    male  InvestmentBanking  Aquarius 2004-06-10   \n",
       "8             9    16332    male  InvestmentBanking  Aquarius 2004-06-10   \n",
       "9            10    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "10           11    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "11           12    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "12           13    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "13           14    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "14           15    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "15           16    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "16           17    16332    male  InvestmentBanking  Aquarius 2004-06-09   \n",
       "17           18    16332    male  InvestmentBanking  Aquarius 2004-06-18   \n",
       "18           19    16332    male  InvestmentBanking  Aquarius 2004-06-17   \n",
       "19           20    16332    male  InvestmentBanking  Aquarius 2004-06-16   \n",
       "20           21    16332    male  InvestmentBanking  Aquarius 2004-06-15   \n",
       "21           22    16332    male  InvestmentBanking  Aquarius 2004-06-14   \n",
       "22           23    16332    male  InvestmentBanking  Aquarius 2004-06-13   \n",
       "23           24    16332    male  InvestmentBanking  Aquarius 2004-06-23   \n",
       "24           25    16332    male  InvestmentBanking  Aquarius 2004-06-22   \n",
       "25           26    16332    male  InvestmentBanking  Aquarius 2004-06-20   \n",
       "26           27    16332    male  InvestmentBanking  Aquarius 2004-07-02   \n",
       "27           28    16332    male  InvestmentBanking  Aquarius 2004-07-01   \n",
       "28           29    16332    male  InvestmentBanking  Aquarius 2004-07-01   \n",
       "29           30    16332    male  InvestmentBanking  Aquarius 2004-06-30   \n",
       "...         ...      ...     ...                ...       ...        ...   \n",
       "442931   681132     8300  female            Student    Pisces 2004-08-07   \n",
       "442932   681133     8300  female            Student    Pisces 2004-08-07   \n",
       "442933   681134     8300  female            Student    Pisces 2004-08-01   \n",
       "442934   681135     8300  female            Student    Pisces 2004-08-01   \n",
       "442935   681136     8300  female            Student    Pisces 2004-08-01   \n",
       "442936   681137     8300  female            Student    Pisces 2004-08-01   \n",
       "442937   681138     8300  female            Student    Pisces 2004-08-01   \n",
       "442938   681139     8300  female            Student    Pisces 2004-08-01   \n",
       "442939   681140     8300  female            Student    Pisces 2004-08-01   \n",
       "442940   681141     8300  female            Student    Pisces 2004-08-01   \n",
       "442941   681142     9132  female        Engineering     Libra 2004-06-20   \n",
       "442942   681143     9132  female        Engineering     Libra 2004-06-19   \n",
       "442943   681144     9132  female        Engineering     Libra 2004-06-14   \n",
       "442944   681145     9132  female        Engineering     Libra 2004-06-14   \n",
       "442945   681146     9132  female        Engineering     Libra 2004-06-14   \n",
       "442946   681147     9132  female        Engineering     Libra 2004-06-13   \n",
       "442947   681148     9132  female        Engineering     Libra 2004-06-12   \n",
       "442948   681149     9132  female        Engineering     Libra 2004-06-09   \n",
       "442949   681150     9132  female        Engineering     Libra 2004-06-09   \n",
       "442950   681151     9132  female        Engineering     Libra 2004-06-07   \n",
       "442951   681152     9132  female        Engineering     Libra 2004-06-07   \n",
       "442952   681153     9132  female        Engineering     Libra 2004-06-07   \n",
       "442953   681154     9132  female        Engineering     Libra 2004-06-06   \n",
       "442954   681155     9132  female        Engineering     Libra 2004-06-06   \n",
       "442955   681156     9132  female        Engineering     Libra 2004-06-06   \n",
       "442956   681157     4593  female             indUnk     Virgo 2004-08-23   \n",
       "442957   681158     4593  female             indUnk     Virgo 2004-08-21   \n",
       "442958   681159     4593  female             indUnk     Virgo 2004-08-19   \n",
       "442959   681160     4593  female             indUnk     Virgo 2004-08-18   \n",
       "442960   681161     4593  female             indUnk     Virgo 2004-08-18   \n",
       "\n",
       "                                                     text age    set  \n",
       "0                  Info has been found (+/- 100 pages,...  15  train  \n",
       "1                  These are the team members:   Drewe...  15  train  \n",
       "2                  In het kader van kernfusie op aarde...  15  train  \n",
       "3                        testing!!!  testing!!!            15  train  \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  33  train  \n",
       "5                    I had an interesting conversation...  33  train  \n",
       "6                    Somehow Coca-Cola has a way of su...  33  train  \n",
       "7                    If anything, Korea is a country o...  33  train  \n",
       "8                    Take a read of this news article ...  33  train  \n",
       "9                    I surf the English news sites a l...  33  train  \n",
       "10                   Ah, the Korean language...it look...  33  train  \n",
       "11                   If you click on my profile you'll...  33  train  \n",
       "12                   Last night was pretty fun...mostl...  33  train  \n",
       "13                   There is so much that is differen...  33  train  \n",
       "14                    urlLink    Here it is, the super...  33  train  \n",
       "15                   One thing I love about Seoul (and...  33  train  \n",
       "16                    urlLink    Wonderful oh-gyup-sal...  33  train  \n",
       "17                   Here is the latest from the Korea...  33  train  \n",
       "18                   Well, I stand corrected, again.  ...  33  train  \n",
       "19                   So I've been in Vancouver a few d...  33  train  \n",
       "20                   Whenever I see a pregnant Korean ...  33  train  \n",
       "21                   My wife posed a strange question ...  33  train  \n",
       "22                   As readers will know, my favorite...  33  train  \n",
       "23                   When I was in Seoul these last fe...  33  train  \n",
       "24                   You may have noticed a new featur...  33  train  \n",
       "25                   Korea, especially Seoul, is prett...  33  train  \n",
       "26                   It seems everything is not all th...  33  train  \n",
       "27                   This may be a long blog...got a l...  33  train  \n",
       "28                   I've always thought of Seoul's  u...  33  train  \n",
       "29                   Big cities are famous for being e...  33  train  \n",
       "...                                                   ...  ..    ...  \n",
       "442931                    urlLink    LeNg LenG ChoO~!!...  13  train  \n",
       "442932                    urlLink    PeaCe~.. hahaz.. ...  13  train  \n",
       "442933                    urlLink    Mé~!!.. hahaz.. a...  13  train  \n",
       "442934                    urlLink    Mý Dá®líng... Sh...  13  train  \n",
       "442935                    urlLink    Ah KiN~!.. hahaz....  13  train  \n",
       "442936                    urlLink    Ah Jun.. &.. HunG...  13  train  \n",
       "442937                    urlLink    GleN ChOnG & KriS...  13  train  \n",
       "442938                    urlLink    Ah Jun~!!.. hahaz...  13  train  \n",
       "442939                    urlLink    ComE~!.. LeT Me I...  13  train  \n",
       "442940                    urlLink    Yi BiAo~!.. hahaz...  13  train  \n",
       "442941     still not feeling oky,i'm losing my voice,....  27  train  \n",
       "442942       'LORD,Please give me the strengh to accep...  27  train  \n",
       "442943     'Godliness with contentment is great gain' ...  27  train  \n",
       "442944     wasn't able to go to work for two days,bad,...  27  train  \n",
       "442945     ow life...i wasn't supposed to go to work l...  27  train  \n",
       "442946     not a good day for ...coz i'm not feeling o...  27  train  \n",
       "442947     1. DREAM NICKNAME:     >> still my nick(lov...  27  train  \n",
       "442948     first day at work again,i haven't gotten en...  27  train  \n",
       "442949     at least i'm abit okay now coz it's the las...  27  train  \n",
       "442950     i used to feel okay  minding my stuff until...  27  train  \n",
       "442951     i dunno understand but i always feel this,e...  27  train  \n",
       "442952     i'm happy today,coz the Lord is giving me l...  27  train  \n",
       "442953     A LITTLE BIT   I was kinda hesitant to tell...  27  train  \n",
       "442954     last night when i was going to work i was a...  27  train  \n",
       "442955     her's my first article,honestly i dunno wha...  27  train  \n",
       "442956                   I ran around cleaning all mor...  34  train  \n",
       "442957                   We just got back from Six Fla...  34  train  \n",
       "442958                    urlLink     I  felt kind of ...  34  train  \n",
       "442959                   Wow, I love fruit.  I read th...  34  train  \n",
       "442960                   I want to consider myself a r...  34  train  \n",
       "\n",
       "[438492 rows x 9 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alldata.set\n",
    "training_corrected.head\n",
    "# testing_corrected.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328869, 9)\n",
      "(109623, 9)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation (did not do the complicated ones we talked about in class)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/cross_validation.html <-- I saw we imported this, but couldn't figure out sklearn\n",
    "\n",
    "cv_train = training_corrected.sample(frac=.75,random_state=42)\n",
    "training_posts = cv_train[\"post.id\"]\n",
    "\n",
    "# https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas\n",
    "\n",
    "cs_val = training_corrected.loc[~training_corrected['post.id'].isin(training_posts)]\n",
    "\n",
    "# note: tilda negates like a - sign would in R\n",
    "\n",
    "print(cv_train.shape)\n",
    "print(cs_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post.id</th>\n",
       "      <th>user.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328869.000000</td>\n",
       "      <td>328869.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>340164.053529</td>\n",
       "      <td>9666.698141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>196650.953130</td>\n",
       "      <td>5518.572128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>168344.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>341968.000000</td>\n",
       "      <td>9643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>510805.000000</td>\n",
       "      <td>14291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>681161.000000</td>\n",
       "      <td>19319.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             post.id        user.id\n",
       "count  328869.000000  328869.000000\n",
       "mean   340164.053529    9666.698141\n",
       "std    196650.953130    5518.572128\n",
       "min         1.000000       1.000000\n",
       "25%    168344.000000    4752.000000\n",
       "50%    341968.000000    9643.000000\n",
       "75%    510805.000000   14291.000000\n",
       "max    681161.000000   19319.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
